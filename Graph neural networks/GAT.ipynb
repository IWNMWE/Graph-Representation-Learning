{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3FeF_JqtXJX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06a2bc2-cd65-48fc-f747-e16767f07a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "import torch_geometric as pyg\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch.nn import Linear, Parameter\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree, is_undirected\n",
        "from torch_geometric.utils import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ez1JYogEG1pV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88382643-40f8-4633-9845-ff2666e803e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = dataset.edge_index\n",
        "x = dataset.x"
      ],
      "metadata": {
        "id": "PCFLVjrILhlu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gattn(MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels, activation=torch.nn.ReLU()):\n",
        "    super().__init__(aggr='add')\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.lin = Linear(in_channels, out_channels, bias=False)\n",
        "    self.att = Linear(2 * out_channels, 1, bias=False)\n",
        "    self.reset_parameters()\n",
        "    self.att_activation  = torch.nn.LeakyReLU(negative_slope=0.2, inplace=False)\n",
        "    self.activation = activation\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self.lin.reset_parameters()\n",
        "    self.att.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "    x = self.lin(x)\n",
        "\n",
        "    att_features = torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=1)\n",
        "    att_coeff = self.att(att_features).squeeze(-1)\n",
        "    att_coeff = torch.exp(self.att_activation(att_coeff))\n",
        "\n",
        "    att_coeff = softmax(att_coeff, edge_index[1])\n",
        "\n",
        "    out = self.propagate(edge_index, x=x, att_coeff=att_coeff)\n",
        "\n",
        "    return self.activation(out)\n",
        "\n",
        "  def message(self, x_j, att_coeff):\n",
        "\n",
        "    return x_j * att_coeff.repeat(x_j.shape[1],1).t()\n",
        "\n"
      ],
      "metadata": {
        "id": "mO5aXPcZLkol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "63ae4f28-f164-4ba9-95fd-93f056749ebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MessagePassing' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9e8ecc166753>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessagePassing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MessagePassing' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.utils import add_self_loops, softmax\n",
        "\n",
        "class Gattn(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3, activation=torch.nn.ReLU()):\n",
        "        super().__init__(aggr='add')\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Linear transformations\n",
        "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
        "        self.att = Linear(2 * out_channels, 1, bias=False)\n",
        "\n",
        "        # Activations\n",
        "        self.att_activation = torch.nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.activation = activation\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.att.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Add self-loops\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Apply linear transformation\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Compute attention\n",
        "        x_i = x[edge_index[0]]  # Source node features\n",
        "        x_j = x[edge_index[1]]  # Target node features\n",
        "\n",
        "        # Attention coefficients\n",
        "        alpha = torch.cat([x_i, x_j], dim=-1)\n",
        "        alpha = self.att(alpha)\n",
        "        alpha = self.att_activation(alpha)\n",
        "        alpha = softmax(alpha.squeeze(), edge_index[1])\n",
        "\n",
        "        # Apply dropout to attention coefficients\n",
        "        alpha = torch.nn.functional.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Propagate\n",
        "        out = self.propagate(edge_index, x=x, alpha=alpha)\n",
        "\n",
        "        return self.activation(out)\n",
        "\n",
        "    def message(self, x_j, alpha):\n",
        "        # Apply attention coefficients\n",
        "        return x_j * alpha.view(-1, 1)"
      ],
      "metadata": {
        "id": "IYg9_qHbABxy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SemiSupervisedClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_embed_dim : int,  num_classes : int, latent_dim = None):\n",
        "        super(SemiSupervisedClassifier, self).__init__()\n",
        "        if latent_dim is None:\n",
        "          latent_dim = input_embed_dim\n",
        "        self.gattn1a = Gattn(input_embed_dim, latent_dim)\n",
        "        self.gattn1b = Gattn(input_embed_dim, latent_dim)\n",
        "        self.gattn2a = Gattn(2 * latent_dim, num_classes)\n",
        "        self.gattn2b = Gattn(2 * latent_dim, num_classes)\n",
        "    def forward(self, H : torch.Tensor, A : torch.Tensor):\n",
        "        x = self.gattn1a(H, A)\n",
        "        x = torch.cat([self.gattn1b(H, A), x], dim=1)\n",
        "        x1 = self.gattn2a(x, A)\n",
        "        x1 = torch.unsqueeze(x1, 0)\n",
        "        x2 = self.gattn2b(x, A)\n",
        "        x2 = torch.unsqueeze(x2, 0)\n",
        "        x = torch.mean(torch.cat([x1, x2]), dim=0)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "jjlzSZgvMJub"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SemiSupervisedClassifier(dataset.x.shape[1], dataset.num_classes)"
      ],
      "metadata": {
        "id": "CeHCQTLu5aCK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(15):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x, edge_index)\n",
        "    loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "XQxXWBKV5eUd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = model(x, edge_index).argmax(dim=1)\n",
        "correct = (pred[dataset.test_mask] == dataset.y[dataset.test_mask]).sum()\n",
        "acc = int(correct) / int(dataset.test_mask.sum())\n",
        "print(f'Accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "id": "f3x6d5BE5g-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e57d8f5-aba3-42a0-c7ff-04169d65a928"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7120\n"
          ]
        }
      ]
    }
  ]
}