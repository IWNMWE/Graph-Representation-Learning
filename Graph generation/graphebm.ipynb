{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"id":"iCvVOBSXdWOc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"66b9bfde-dc89-45fc-fb22-8538e1bce322","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:43:38.046495Z","iopub.execute_input":"2025-06-22T07:43:38.047037Z","iopub.status.idle":"2025-06-22T07:43:42.898947Z","shell.execute_reply.started":"2025-06-22T07:43:38.047010Z","shell.execute_reply":"2025-06-22T07:43:42.898248Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch import Tensor\nimport torch.nn.functional as F\n\nfrom torch_geometric.data import Data\nfrom torch_geometric.transforms import BaseTransform\nfrom torch_geometric.transforms import ToDense\n\n\nclass ToGraphEBM(BaseTransform):\n    def __init__(self,max_nodes = 38, n_atoms = 28, n_edge_types = 3):\n        self.max_nodes = max_nodes\n        self.n_atoms = n_atoms\n        \n    def forward(self, data : Data):\n        nodes, _ = data.x.shape\n        \n        \n        # adding virtual nodes if max nodes not present\n        if data.x.shape[0] < self.max_nodes:\n            virt_rows = torch.ones([self.max_nodes - data.x.shape[0], 1])\n            virt_rows = virt_rows * self.n_atoms\n            data.x = torch.cat([data.x, virt_rows], dim=0)\n        data.x = F.one_hot(data.x.squeeze().long(), num_classes = self.n_atoms + 1)\n        \n        return data\n        \nclass ToDenseAdj(BaseTransform):\n    def __init__(self,max_nodes = 38, n_atoms = 28, n_edge_types = 3):\n        self.max_nodes = max_nodes\n        self.n_atoms = n_atoms\n        self.trans = ToDense(num_nodes=38)\n        self.n_edge_types = n_edge_types \n\n    def forward(self, data : Data):\n        \n        # working with dense dataset and adding virtual edges\n        d = self.trans(data)\n        adj = d.adj\n        adj_mask = (adj > 0) * 1\n        adj = F.one_hot(adj.long(), num_classes = self.n_edge_types + 1)\n        adj[:, :, 0] = adj[:, :, 0] * adj_mask\n        adj[:,:,-1] = torch.logical_not(torch.any(adj,dim=-1, keepdim=False)) * 1\n        for i in range(adj.shape[0]):\n            adj[i,i,:] = 0\n        d.adj = adj.permute(2,0,1)\n        \n        return d\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:43:42.900582Z","iopub.execute_input":"2025-06-22T07:43:42.901156Z","iopub.status.idle":"2025-06-22T07:43:47.687358Z","shell.execute_reply.started":"2025-06-22T07:43:42.901131Z","shell.execute_reply":"2025-06-22T07:43:47.686800Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch_geometric as pyg\nfrom torch_geometric.transforms import ToDense\n\ndataset = pyg.datasets.ZINC(root='/kaggle/working/', transform = ToDenseAdj(),pre_transform=ToGraphEBM())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:43:47.688560Z","iopub.execute_input":"2025-06-22T07:43:47.688963Z","iopub.status.idle":"2025-06-22T07:45:50.494365Z","shell.execute_reply.started":"2025-06-22T07:43:47.688939Z","shell.execute_reply":"2025-06-22T07:45:50.493774Z"}},"outputs":[{"name":"stderr","text":"Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\nExtracting /kaggle/working/molecules.zip\nDownloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\nDownloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\nDownloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\nProcessing...\nProcessing train dataset: 100%|██████████| 220011/220011 [00:43<00:00, 5065.17it/s]\nProcessing val dataset: 100%|██████████| 24445/24445 [00:05<00:00, 4274.72it/s]\nProcessing test dataset: 100%|██████████| 5000/5000 [00:01<00:00, 3303.89it/s]\nDone!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from torch_geometric.loader import DenseDataLoader\n\nloader = DenseDataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:50.495202Z","iopub.execute_input":"2025-06-22T07:45:50.495503Z","iopub.status.idle":"2025-06-22T07:45:50.501071Z","shell.execute_reply.started":"2025-06-22T07:45:50.495477Z","shell.execute_reply":"2025-06-22T07:45:50.500560Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os\nimport torch_geometric as pyg\nfrom torch_geometric.transforms import ToDense\nfrom torch_geometric.loader import DenseDataLoader\nfrom torch.nn.utils import spectral_norm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"id":"GscjPo16Jdof","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:50.503304Z","iopub.execute_input":"2025-06-22T07:45:50.503764Z","iopub.status.idle":"2025-06-22T07:45:51.614396Z","shell.execute_reply.started":"2025-06-22T07:45:50.503739Z","shell.execute_reply":"2025-06-22T07:45:51.613555Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class GraphConv(nn.Module):\n\n    def __init__(self, in_channels, out_channels, num_edge_type=4, add_self=False):\n        super(GraphConv, self).__init__()\n\n        self.add_self = add_self\n        if self.add_self:\n            self.linear_node = spectral_norm(nn.Linear(in_channels, out_channels))\n        self.linear_edge = spectral_norm(nn.Linear(in_channels, out_channels * num_edge_type))\n        self.num_edge_type = num_edge_type\n        self.in_ch = in_channels\n        self.out_ch = out_channels\n\n    def forward(self, adj, h):\n        mb, node, _ = h.shape\n        if self.add_self:\n            h_node = self.linear_node(h)\n        m = self.linear_edge(h)\n        m = m.reshape(mb, node, self.out_ch, self.num_edge_type)\n        m = m.permute(0, 3, 1, 2) # m: (batchsize, edge_type, node, ch)\n        hr = torch.matmul(adj, m)  # hr: (batchsize, edge_type, node, ch)\n        hr = hr.sum(dim=1)   # hr: (batchsize, node, ch)\n        if self.add_self:\n            return hr+h_node  #\n        else:\n            return hr","metadata":{"id":"nExFdhYbYBUB","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:51.615197Z","iopub.execute_input":"2025-06-22T07:45:51.615430Z","iopub.status.idle":"2025-06-22T07:45:52.567904Z","shell.execute_reply.started":"2025-06-22T07:45:51.615414Z","shell.execute_reply":"2025-06-22T07:45:52.567081Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class EnergyFunction(nn.Module):\n\n  def __init__(self, in_channels, num_edge_type, latent_channels, layers):\n    super(EnergyFunction, self).__init__()\n    self.conv1 = GraphConv(in_channels, latent_channels, num_edge_type, add_self=True)\n    self.conv_list = nn.ModuleList([GraphConv(latent_channels, latent_channels) for i in range(layers-1)])\n    self.linear = nn.Linear(latent_channels, 1)\n    self.layers = layers\n    self.latent_channels = latent_channels\n\n  def forward(self, adj, h):\n    h = self.conv1(adj, h)\n    h = F.relu(h)\n    for i in range(self.layers-1):\n      h = self.conv_list[i](adj, h)\n      h = F.relu(h)\n    h = torch.sum(h, dim=1)\n    energy = self.linear(h)\n    return energy\n","metadata":{"id":"5aisEKYFYxe8","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:52.568889Z","iopub.execute_input":"2025-06-22T07:45:52.569100Z","iopub.status.idle":"2025-06-22T07:45:56.957913Z","shell.execute_reply.started":"2025-06-22T07:45:52.569084Z","shell.execute_reply":"2025-06-22T07:45:56.957255Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def normalize_adj(adj):\n    degree = adj.sum(dim=(1,2))\n    degree_inv = degree.pow(-1) \n    diags_inv = [torch.diag(degree_inv[i, :]) for i in range(adj.shape[0])]\n    D_inv = torch.stack(diags_inv, dim=0)\n    s = [1 for i in range(len(D_inv.shape))]\n    s.append(adj.shape[1])\n    D_inv = D_inv.unsqueeze(-1).repeat(s).permute(0,3,1,2)\n    adj_pos = torch.matmul(D_inv, adj)\n    return adj_pos\n    \ndef requires_grad(parameters, flag):\n    for p in parameters:\n        p.requires_grad = flag","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:56.958588Z","iopub.execute_input":"2025-06-22T07:45:56.958760Z","iopub.status.idle":"2025-06-22T07:45:56.971895Z","shell.execute_reply.started":"2025-06-22T07:45:56.958745Z","shell.execute_reply":"2025-06-22T07:45:56.971191Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class GraphEBM():\n  def __init__(self, num_nodes, num_atoms, num_edges, latent_size, layers, device):\n      self.energy_function = EnergyFunction(num_atoms, num_edges, latent_size, layers).to(device)\n      self.num_nodes = num_nodes\n      self.num_atoms = num_atoms\n      self.num_edges = num_edges\n      self.device = device\n\n  def train_rand(self, loader, lr, wd, max_epochs, c, ld_step, ld_noise_std, ld_step_size, clamp, alpha, save_dir):\n     \n     parameters = self.energy_function.parameters()\n     optimizer = torch.optim.Adam(parameters, lr=lr, betas=(0.0, 0.999), weight_decay=wd)\n     for epoch in range(max_epochs):\n         l_loss = []\n         l_loss_energy= []\n         l_loss_reg = []\n         for _, batch in enumerate(tqdm(loader)):\n         \n             pos_x = batch.x.to(self.device).to(dtype=torch.float32)\n             pos_adj = batch.adj.to(self.device).to(dtype=torch.float32)\n\n             # dequantization\n             pos_x += c * torch.rand_like(pos_x, device=self.device)\n             pos_adj += c * torch.rand_like(pos_adj, device=self.device)\n             pos_adj = normalize_adj(pos_adj)\n\n             neg_x = torch.rand_like(pos_x, device=self.device) * (1 + c)\n             neg_adj = torch.rand_like(pos_adj, device=self.device)\n\n             noise_x = torch.rand_like(pos_x, device=self.device)\n             noise_adj = torch.rand_like(pos_adj, device=self.device)\n             neg_x.requires_grad =True\n             neg_adj.requires_grad= True\n             for _ in range(ld_step):\n\n                 noise_x.normal_(0, ld_noise_std)\n                 noise_adj.normal_(0, ld_noise_std)\n             \n                 # calculate energy gradient wrt negative data\n                 neg_energy = self.energy_function(neg_adj, neg_x)\n                 neg_energy.sum().backward()\n\n                 if (clamp):\n                     neg_x.grad.clamp_(-0.01, 0.01)\n                     neg_adj.grad.clamp_(-0.01, 0.01)\n                 \n                 # langevin steps\n                 neg_x.data.add_(noise_x.data)\n                 neg_adj.data.add_(noise_adj.data)\n                 neg_x.data.add_(neg_x.grad.data, alpha=-ld_step_size)\n                 neg_adj.data.add_(neg_adj.grad.data, alpha=-ld_step_size)\n             \n                 # manual zero step since optims are not used\n                 neg_x.grad.detach_()\n                 neg_x.grad.zero_()\n                 neg_adj.grad.detach_()\n                 neg_adj.grad.zero_()\n\n                 # ensuring value ranges\n                 neg_x.data.clamp_(0, 1 + c)\n                 neg_adj.data.clamp_(0, 1)\n\n\n             neg_adj.requires_grad = False\n             neg_x.requires_grad = False\n             requires_grad(parameters, True)\n             neg_energy = self.energy_function(neg_adj, neg_x)\n             pos_energy = self.energy_function(pos_adj, pos_x)\n             loss_energy = (pos_energy - neg_energy).mean()\n             loss_reg = (pos_energy ** 2 + neg_energy ** 2).mean()\n             loss = loss_energy + alpha * loss_reg \n             optimizer.zero_grad()\n             loss.backward()\n             optimizer.step()\n             l_loss_energy.append(loss_energy)\n             l_loss_reg.append(loss_reg)\n             l_loss.append(loss)\n         print('Epoch: {:03d}, Loss: {:.6f}, Energy Loss: {:.6f}, Regularizer Loss: {:.6f}'.format(epoch+1, (sum(l_loss)/len(l_loss)).item(), (sum(l_loss_energy)/len(l_loss_energy)).item(), (sum(l_loss_reg)/len(l_loss_reg)).item()))\n         if((epoch + 1 % 5) == 0):\n             torch.save(self.energy_function, save_dir)\n  def gen_rand(self, n_molecules, c, ld_step, ld_noise_std, ld_step_size, clamp):\n         \n         gen_x = torch.rand(n_molecules, self.num_nodes, self.num_atoms, device=self.device) * (1 + c)\n         gen_adj = torch.rand(n_molecules, self.num_nodes, self.num_nodes, self.num_edges, device=self.device)\n\n         noise_x = torch.rand_like(gen_x, device=self.device)\n         noise_adj = torch.rand_like(gen_adj, device=self.device)\n         gen_x.requires_grad = True\n         gen_adj.requires_grad = True\n         for _ in range(ld_step):\n\n             noise_x.normal_(0, ld_noise_std)\n             noise_adj.normal_(0, ld_noise_std)\n\n             # calculate energy gradient wrt generated data\n             gen_energy = self.energy_function(gen_adj, gen_x)\n             gen_energy = gen_energy.sum()\n             gen_energy.backward()\n\n             if (clamp):\n                 gen_x.grad.clamp_(-0.01, 0.01)\n                 gen_adj.grad.clamp_(-0.01, 0.01)\n                 \n             # langevin steps\n             gen_x.data.add_(noise_x.data)\n             gen_adj.data.add_(noise_adj.data)\n             gen_x.data.add_(gen_x.grad.data, alpha=-ld_step_size)\n             gen_adj.data.add_(gen_adj.grad.data, alpha=-ld_step_size)\n             \n             # manual zero step since optims are not used\n             gen_x.grad.detach_()\n             gen_x.grad.zero_()\n             gen_adj.grad.detach_()\n             gen_adj.grad.zero_()\n\n             # ensuring value ranges\n             gen_x.data.clamp_(0, 1 + c)\n             gen_adj.data.clamp_(0, 1)\n\n         gen_adj += gen_adj.permute(0, 2, 1, 3)\n         gen_adj  = gen_adj * 0.5\n         return gen_adj        ","metadata":{"id":"YQubsSAPoC15","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:56.972704Z","iopub.execute_input":"2025-06-22T07:45:56.972939Z","iopub.status.idle":"2025-06-22T07:45:56.991241Z","shell.execute_reply.started":"2025-06-22T07:45:56.972917Z","shell.execute_reply":"2025-06-22T07:45:56.990730Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = GraphEBM( num_nodes=38, num_atoms = 29, num_edges = 4, latent_size = 64, layers = 2, device=torch.device('cuda'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:56.991920Z","iopub.execute_input":"2025-06-22T07:45:56.992095Z","iopub.status.idle":"2025-06-22T07:45:57.166840Z","shell.execute_reply.started":"2025-06-22T07:45:56.992081Z","shell.execute_reply":"2025-06-22T07:45:57.166331Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model.train_rand(loader, lr=1e-4, wd=0, max_epochs=5, c=0, ld_step=150, ld_noise_std=0.005, ld_step_size=30, clamp=True, alpha=1,save_dir='/kaggle/working/model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T07:45:57.168821Z","iopub.execute_input":"2025-06-22T07:45:57.169024Z","iopub.status.idle":"2025-06-22T12:49:24.554320Z","shell.execute_reply.started":"2025-06-22T07:45:57.169010Z","shell.execute_reply":"2025-06-22T12:49:24.553698Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6876/6876 [59:53<00:00,  1.91it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 001, Loss: 360551.843750, Energy Loss: 81.415825, Regularizer Loss: 360470.906250\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6876/6876 [1:00:53<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 002, Loss: 747.655762, Energy Loss: -0.591725, Regularizer Loss: 748.250366\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6876/6876 [1:00:45<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 003, Loss: 25.795780, Energy Loss: -1.015117, Regularizer Loss: 26.810881\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6876/6876 [1:00:56<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 004, Loss: 0.729441, Energy Loss: -0.998932, Regularizer Loss: 1.728377\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6876/6876 [1:00:54<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 005, Loss: 0.005470, Energy Loss: -0.995745, Regularizer Loss: 1.001217\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"torch.save(model.energy_function, '/kaggle/working/model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T13:28:42.935520Z","iopub.execute_input":"2025-06-22T13:28:42.935824Z","iopub.status.idle":"2025-06-22T13:28:43.107088Z","shell.execute_reply.started":"2025-06-22T13:28:42.935803Z","shell.execute_reply":"2025-06-22T13:28:43.106337Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}