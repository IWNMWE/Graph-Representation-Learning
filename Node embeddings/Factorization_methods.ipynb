{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulNFjOFDx_hF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.zeros(10, 10, requires_grad=False)\n",
        "\n",
        "for i in range(10):\n",
        "  for j in range(10):\n",
        "    if (random.random() > 0.5):\n",
        "      A[i , j] = 1"
      ],
      "metadata": {
        "id": "NeVGYmeI581G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphFact(torch.nn.Module):\n",
        "  def __init__(self, num_nodes, embd_dim):\n",
        "    super(GraphFact, self).__init__()\n",
        "    self.H = torch.nn.Parameter(torch.rand(num_nodes, embd_dim))\n",
        "    self.reset_param()\n",
        "\n",
        "  def reset_param(self):\n",
        "    torch.nn.init.xavier_uniform_(self.H)\n",
        "\n",
        "  def forward(self, A : torch):\n",
        "    H = self.H.clone()\n",
        "    Ht = torch.transpose(H, 0, 1)\n",
        "    sim = torch.mm(H, Ht)\n",
        "    return torch.sum(torch.pow(sim - A,2))\n"
      ],
      "metadata": {
        "id": "FoO43XrD973H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphFact(10, 16)\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "k = 3\n",
        "Ak = A.clone()\n",
        "for i in range(k):\n",
        "  Ak = torch.mm(Ak, A)\n",
        "\n",
        "for i in range(200):\n",
        "    loss = model(A)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI_tUlCvvkq2",
        "outputId": "42053f2b-85d6-45e1-ca3a-961a4dfb13fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(53.9929, grad_fn=<SumBackward0>)\n",
            "tensor(53.9929, grad_fn=<SumBackward0>)\n",
            "tensor(44.7307, grad_fn=<SumBackward0>)\n",
            "tensor(37.1120, grad_fn=<SumBackward0>)\n",
            "tensor(31.4438, grad_fn=<SumBackward0>)\n",
            "tensor(26.9906, grad_fn=<SumBackward0>)\n",
            "tensor(23.4865, grad_fn=<SumBackward0>)\n",
            "tensor(20.9263, grad_fn=<SumBackward0>)\n",
            "tensor(19.2607, grad_fn=<SumBackward0>)\n",
            "tensor(18.2869, grad_fn=<SumBackward0>)\n",
            "tensor(17.7218, grad_fn=<SumBackward0>)\n",
            "tensor(17.3422, grad_fn=<SumBackward0>)\n",
            "tensor(17.0440, grad_fn=<SumBackward0>)\n",
            "tensor(16.7990, grad_fn=<SumBackward0>)\n",
            "tensor(16.5975, grad_fn=<SumBackward0>)\n",
            "tensor(16.4295, grad_fn=<SumBackward0>)\n",
            "tensor(16.2870, grad_fn=<SumBackward0>)\n",
            "tensor(16.1645, grad_fn=<SumBackward0>)\n",
            "tensor(16.0589, grad_fn=<SumBackward0>)\n",
            "tensor(15.9673, grad_fn=<SumBackward0>)\n",
            "tensor(15.8879, grad_fn=<SumBackward0>)\n",
            "tensor(15.8186, grad_fn=<SumBackward0>)\n",
            "tensor(15.7583, grad_fn=<SumBackward0>)\n",
            "tensor(15.7055, grad_fn=<SumBackward0>)\n",
            "tensor(15.6593, grad_fn=<SumBackward0>)\n",
            "tensor(15.6188, grad_fn=<SumBackward0>)\n",
            "tensor(15.5833, grad_fn=<SumBackward0>)\n",
            "tensor(15.5521, grad_fn=<SumBackward0>)\n",
            "tensor(15.5247, grad_fn=<SumBackward0>)\n",
            "tensor(15.5006, grad_fn=<SumBackward0>)\n",
            "tensor(15.4793, grad_fn=<SumBackward0>)\n",
            "tensor(15.4605, grad_fn=<SumBackward0>)\n",
            "tensor(15.4439, grad_fn=<SumBackward0>)\n",
            "tensor(15.4292, grad_fn=<SumBackward0>)\n",
            "tensor(15.4162, grad_fn=<SumBackward0>)\n",
            "tensor(15.4046, grad_fn=<SumBackward0>)\n",
            "tensor(15.3944, grad_fn=<SumBackward0>)\n",
            "tensor(15.3853, grad_fn=<SumBackward0>)\n",
            "tensor(15.3772, grad_fn=<SumBackward0>)\n",
            "tensor(15.3699, grad_fn=<SumBackward0>)\n",
            "tensor(15.3634, grad_fn=<SumBackward0>)\n",
            "tensor(15.3576, grad_fn=<SumBackward0>)\n",
            "tensor(15.3525, grad_fn=<SumBackward0>)\n",
            "tensor(15.3478, grad_fn=<SumBackward0>)\n",
            "tensor(15.3436, grad_fn=<SumBackward0>)\n",
            "tensor(15.3399, grad_fn=<SumBackward0>)\n",
            "tensor(15.3365, grad_fn=<SumBackward0>)\n",
            "tensor(15.3335, grad_fn=<SumBackward0>)\n",
            "tensor(15.3307, grad_fn=<SumBackward0>)\n",
            "tensor(15.3282, grad_fn=<SumBackward0>)\n",
            "tensor(15.3260, grad_fn=<SumBackward0>)\n",
            "tensor(15.3239, grad_fn=<SumBackward0>)\n",
            "tensor(15.3221, grad_fn=<SumBackward0>)\n",
            "tensor(15.3204, grad_fn=<SumBackward0>)\n",
            "tensor(15.3189, grad_fn=<SumBackward0>)\n",
            "tensor(15.3175, grad_fn=<SumBackward0>)\n",
            "tensor(15.3163, grad_fn=<SumBackward0>)\n",
            "tensor(15.3151, grad_fn=<SumBackward0>)\n",
            "tensor(15.3141, grad_fn=<SumBackward0>)\n",
            "tensor(15.3131, grad_fn=<SumBackward0>)\n",
            "tensor(15.3122, grad_fn=<SumBackward0>)\n",
            "tensor(15.3114, grad_fn=<SumBackward0>)\n",
            "tensor(15.3107, grad_fn=<SumBackward0>)\n",
            "tensor(15.3100, grad_fn=<SumBackward0>)\n",
            "tensor(15.3094, grad_fn=<SumBackward0>)\n",
            "tensor(15.3088, grad_fn=<SumBackward0>)\n",
            "tensor(15.3083, grad_fn=<SumBackward0>)\n",
            "tensor(15.3079, grad_fn=<SumBackward0>)\n",
            "tensor(15.3074, grad_fn=<SumBackward0>)\n",
            "tensor(15.3070, grad_fn=<SumBackward0>)\n",
            "tensor(15.3066, grad_fn=<SumBackward0>)\n",
            "tensor(15.3063, grad_fn=<SumBackward0>)\n",
            "tensor(15.3060, grad_fn=<SumBackward0>)\n",
            "tensor(15.3057, grad_fn=<SumBackward0>)\n",
            "tensor(15.3054, grad_fn=<SumBackward0>)\n",
            "tensor(15.3052, grad_fn=<SumBackward0>)\n",
            "tensor(15.3049, grad_fn=<SumBackward0>)\n",
            "tensor(15.3047, grad_fn=<SumBackward0>)\n",
            "tensor(15.3045, grad_fn=<SumBackward0>)\n",
            "tensor(15.3044, grad_fn=<SumBackward0>)\n",
            "tensor(15.3042, grad_fn=<SumBackward0>)\n",
            "tensor(15.3040, grad_fn=<SumBackward0>)\n",
            "tensor(15.3039, grad_fn=<SumBackward0>)\n",
            "tensor(15.3037, grad_fn=<SumBackward0>)\n",
            "tensor(15.3036, grad_fn=<SumBackward0>)\n",
            "tensor(15.3035, grad_fn=<SumBackward0>)\n",
            "tensor(15.3034, grad_fn=<SumBackward0>)\n",
            "tensor(15.3033, grad_fn=<SumBackward0>)\n",
            "tensor(15.3032, grad_fn=<SumBackward0>)\n",
            "tensor(15.3031, grad_fn=<SumBackward0>)\n",
            "tensor(15.3030, grad_fn=<SumBackward0>)\n",
            "tensor(15.3029, grad_fn=<SumBackward0>)\n",
            "tensor(15.3029, grad_fn=<SumBackward0>)\n",
            "tensor(15.3028, grad_fn=<SumBackward0>)\n",
            "tensor(15.3027, grad_fn=<SumBackward0>)\n",
            "tensor(15.3027, grad_fn=<SumBackward0>)\n",
            "tensor(15.3026, grad_fn=<SumBackward0>)\n",
            "tensor(15.3026, grad_fn=<SumBackward0>)\n",
            "tensor(15.3025, grad_fn=<SumBackward0>)\n",
            "tensor(15.3025, grad_fn=<SumBackward0>)\n",
            "tensor(15.3024, grad_fn=<SumBackward0>)\n",
            "tensor(15.3024, grad_fn=<SumBackward0>)\n",
            "tensor(15.3024, grad_fn=<SumBackward0>)\n",
            "tensor(15.3023, grad_fn=<SumBackward0>)\n",
            "tensor(15.3023, grad_fn=<SumBackward0>)\n",
            "tensor(15.3023, grad_fn=<SumBackward0>)\n",
            "tensor(15.3022, grad_fn=<SumBackward0>)\n",
            "tensor(15.3022, grad_fn=<SumBackward0>)\n",
            "tensor(15.3022, grad_fn=<SumBackward0>)\n",
            "tensor(15.3021, grad_fn=<SumBackward0>)\n",
            "tensor(15.3021, grad_fn=<SumBackward0>)\n",
            "tensor(15.3021, grad_fn=<SumBackward0>)\n",
            "tensor(15.3021, grad_fn=<SumBackward0>)\n",
            "tensor(15.3021, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3020, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3019, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3018, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n",
            "tensor(15.3017, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-W4_uGxfUVo",
        "outputId": "3273e045-0556-4806-b0cd-ab813f0695bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 1., 0., 1., 0., 1., 0.],\n",
              "        [0., 1., 1., 0., 1., 1., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
              "        [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 1., 1., 0., 0., 1., 0., 1.],\n",
              "        [1., 0., 0., 0., 0., 1., 1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(model.H, model.H.t())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaqEVBSc89yF",
        "outputId": "5ec0fd97-2a2d-4885-ef1d-7c8300b15669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2952,  0.8214,  0.2570,  0.4972,  0.1808,  0.5272,  0.8839,  0.4185,\n",
              "          0.6651,  0.5233],\n",
              "        [ 0.8214,  1.3833,  0.5684,  0.1157, -0.0546,  0.8523,  0.6767,  0.3740,\n",
              "          0.1475,  0.1694],\n",
              "        [ 0.2570,  0.5684,  0.6239,  0.2577,  0.1744,  0.5669,  0.3836,  0.4846,\n",
              "          0.3129,  0.3395],\n",
              "        [ 0.4972,  0.1157,  0.2577,  0.7612,  0.8061,  0.1757,  0.6052,  0.5620,\n",
              "          0.6804,  0.1344],\n",
              "        [ 0.1808, -0.0546,  0.1744,  0.8061,  1.2529,  0.3567,  0.5029,  0.5083,\n",
              "          0.7317,  0.1231],\n",
              "        [ 0.5272,  0.8523,  0.5669,  0.1757,  0.3567,  1.2046,  0.5207,  0.3623,\n",
              "          0.5245,  0.8521],\n",
              "        [ 0.8839,  0.6767,  0.3836,  0.6052,  0.5029,  0.5207,  0.7868,  0.5469,\n",
              "          0.6375,  0.3182],\n",
              "        [ 0.4185,  0.3740,  0.4846,  0.5620,  0.5083,  0.3623,  0.5469,  0.5892,\n",
              "          0.5219,  0.2111],\n",
              "        [ 0.6651,  0.1475,  0.3129,  0.6804,  0.7317,  0.5245,  0.6375,  0.5219,\n",
              "          0.8800,  0.6923],\n",
              "        [ 0.5233,  0.1694,  0.3395,  0.1344,  0.1231,  0.8521,  0.3182,  0.2111,\n",
              "          0.6923,  1.2634]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see **most** of the nodes that were originally neighbours in the graph are given a higher similary than the ones that are not neighbours.\n",
        "\n",
        "The k can be increased and experimeted with (k refers to the existance of a k length path from one node to another and control what info you optimize against) and acts as teh similarity measure in the graph factorization methods"
      ],
      "metadata": {
        "id": "vJd22-Yeo1TS"
      }
    }
  ]
}